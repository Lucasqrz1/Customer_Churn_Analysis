{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e91acc",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa95b61",
   "metadata": {},
   "source": [
    "This dataset was scraped from kaggle.com on \"Telco Customer Churn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f3fa8f",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38280421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0f82eb",
   "metadata": {},
   "source": [
    "# Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Telco_Customer_Churn.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(\"-\" * 50)\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(\"-\" * 50)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(\"-\" * 50)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf236b",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf48a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(\"-\" * 50)\n",
    "display(df.isnull().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df = df.fillna(method='ffill')  # Forward fill - adjust method based on your needs\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    if col != 'customerID':  # Exclude ID column\n",
    "        print(f\"\\nUnique values in {col}:\")\n",
    "        print(df[col].value_counts())\n",
    "\n",
    "# Convert binary categorical variables to numerical\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Handle other categorical variables using one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=[col for col in categorical_columns if col != 'customerID' and col != 'Churn'])\n",
    "\n",
    "# Display the transformed dataset\n",
    "print(\"\\nTransformed dataset shape:\", df_encoded.shape)\n",
    "display(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb2af7c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd976118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 1. Churn Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "churn_dist = df['Churn'].value_counts()\n",
    "sns.barplot(x=churn_dist.index, y=churn_dist.values)\n",
    "plt.title('Distribution of Customer Churn')\n",
    "plt.xlabel('Churn Status')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 2. Numerical Features Distribution\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    if col != 'Churn':\n",
    "        plt.subplot(3, 3, i)\n",
    "        sns.histplot(data=df, x=col, hue='Churn', multiple=\"stack\")\n",
    "        plt.title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Correlation Analysis\n",
    "correlation_matrix = df_encoded.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.show()\n",
    "\n",
    "# 4. Categorical Features Analysis\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(categorical_cols[:6], 1):\n",
    "    if col != 'customerID':\n",
    "        plt.subplot(2, 3, i)\n",
    "        sns.countplot(data=df, x=col, hue='Churn')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(f'{col} vs Churn')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e64b8",
   "metadata": {},
   "source": [
    "# Feature Engineering and Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Prepare features and target\n",
    "X = df_encoded.drop(['customerID', 'Churn'], axis=1)\n",
    "y = df_encoded['Churn']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
